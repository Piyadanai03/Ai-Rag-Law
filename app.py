import os
import json
import faiss
import torch
import numpy as np
import requests
from typing import List
from tqdm import tqdm
from sentence_transformers import SentenceTransformer
from flask import Flask, request, jsonify, render_template

# ===== CONFIG =====
OLLAMA_URL = "http://localhost:11434/api/generate"
OLLAMA_MODEL = "llama3.2"

FOLDER_LAW = ["data", "family"]
FOLDER_LAWYER = ["lawyer"]

INDEX_LAW = "embeddings/faiss_law.index"
INDEX_LAWYER = "embeddings/faiss_lawyer.index"

TEXTS_LAW = "cache/law.json"
TEXTS_LAWYER = "cache/lawyer.json"

# ===== INIT =====
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"üñ•Ô∏è ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ö‡∏ô: {device.upper()}")

app = Flask(__name__)
embedder = SentenceTransformer("intfloat/multilingual-e5-base")
embedder.to(device)

# ===== GLOBAL =====
law_texts, lawyer_texts = [], []
law_index, lawyer_index = None, None
lawyer_data = []

# ===== LOAD FUNCTIONS =====
def load_json_files(folder_paths: List[str]):
    """‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå JSON ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå ‡πÅ‡∏•‡∏∞‡∏£‡∏ß‡∏° list ‡∏Ç‡πâ‡∏≤‡∏á‡πÉ‡∏ô‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏•‡∏¥‡∏™‡∏ï‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß"""
    texts = []
    for folder in folder_paths:
        if not os.path.exists(folder):
            continue
        json_files = [f for f in os.listdir(folder) if f.endswith(".json")]
        for filename in tqdm(json_files, desc=f"üìö ‡πÇ‡∏´‡∏•‡∏î {folder}"):
            path = os.path.join(folder, filename)
            try:
                with open(path, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    if isinstance(data, list):
                        texts.extend(data)
                    else:
                        texts.append(data)
            except Exception as e:
                print(f"‚ö†Ô∏è ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå {filename} ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ: {e}")
    return texts


def embed_texts(texts: List[str], batch_size: int = 16):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á embedding ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""
    if not texts:
        raise ValueError("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings")
    return embedder.encode(
        texts,
        batch_size=batch_size,
        show_progress_bar=True,
        convert_to_numpy=True,
        normalize_embeddings=True,
        device=device
    )


def build_index(embeddings: np.ndarray):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏î‡∏±‡∏ä‡∏ô‡∏µ FAISS ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á GPU ‡πÅ‡∏•‡∏∞ CPU"""
    print("üìè Embedding shape:", np.shape(embeddings))
    if embeddings is None or len(embeddings) == 0:
        raise ValueError("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏î‡∏±‡∏ä‡∏ô‡∏µ (index)")

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á index ‡πÅ‡∏ö‡∏ö Inner Product (‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö cosine similarity)
    index = faiss.IndexFlatIP(embeddings.shape[1])

    # ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏ß‡πà‡∏≤‡∏°‡∏µ GPU ‡∏Ç‡∏≠‡∏á FAISS ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà (Windows ‡πÑ‡∏°‡πà‡∏°‡∏µ)
    if device == "cuda" and hasattr(faiss, "StandardGpuResources"):
        try:
            print("‚ö° ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô FAISS GPU acceleration")
            res = faiss.StandardGpuResources()
            index = faiss.index_cpu_to_gpu(res, 0, index)
        except Exception as e:
            print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ GPU ‡πÑ‡∏î‡πâ: {e} ‚Üí ‡πÉ‡∏ä‡πâ CPU ‡πÅ‡∏ó‡∏ô")
    else:
        print("üß† ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô FAISS CPU")

    index.add(embeddings)
    return index


def search_similar(query: str, texts: List[str], index, top_k=5, threshold=0.5):
    """‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î"""
    query_emb = embedder.encode([query], convert_to_numpy=True, normalize_embeddings=True, device=device)
    scores, indices = index.search(query_emb, top_k)
    results = []
    for idx, i in enumerate(indices[0]):
        score = scores[0][idx]
        if score >= threshold:
            results.append((texts[i], float(score)))
    return results if results else [(texts[i], float(scores[0][idx])) for idx, i in enumerate(indices[0])]


# ===== BUILD KNOWLEDGE =====
def build_law_dataset():
    """‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á embedding ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢"""
    law_data = load_json_files(FOLDER_LAW)
    law_texts = []
    for d in law_data:
        if isinstance(d, dict) and "section_content" in d and "law_name" in d:
            law_texts.append(f"{d['law_name']} ‡∏°‡∏≤‡∏ï‡∏£‡∏≤ {d['section_num']}:\n{d['section_content']}")
    if not law_texts:
        raise ValueError("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå (law_texts ‡∏ß‡πà‡∏≤‡∏á)")
    print(f"‚úÖ ‡∏û‡∏ö {len(law_texts)} ‡∏°‡∏≤‡∏ï‡∏£‡∏≤‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á embedding")
    emb = embed_texts(law_texts)
    index = build_index(emb)
    return law_texts, index


def build_lawyer_dataset():
    """‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á embedding ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏ô‡∏≤‡∏¢"""
    lawyer_data = load_json_files(FOLDER_LAWYER)
    lawyer_texts = []
    for l in lawyer_data:
        if "name" in l and "expertise" in l:
            lawyer_texts.append(f"{l['name']} - ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç: {', '.join(l['expertise'])}")
    if not lawyer_texts:
        raise ValueError("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏ô‡∏≤‡∏¢‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå (lawyer_texts ‡∏ß‡πà‡∏≤‡∏á)")
    print(f"‚úÖ ‡∏û‡∏ö {len(lawyer_texts)} ‡∏ó‡∏ô‡∏≤‡∏¢‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á embedding")
    emb = embed_texts(lawyer_texts)
    index = build_index(emb)
    return lawyer_data, lawyer_texts, index


# ===== AI UTILITIES =====
def generate_answer(context: str, lawyers: List[dict], query: str):
    """‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Ollama ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö"""
    lawyer_suggestions = "\n".join([
        f"- {l['name']} ({', '.join(l['expertise'])})" for l in lawyers
    ])
    prompt = f"""
‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Ç‡πâ‡∏≠‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢

‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {query}

‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á:
{context}

‡∏ó‡∏ô‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡πÉ‡∏ô‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ô‡∏µ‡πâ:
{lawyer_suggestions}

‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡πÇ‡∏î‡∏¢:
1. ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢
2. ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏°‡∏≤‡∏ï‡∏£‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á
3. ‡∏¢‡∏Å‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
4. ‡∏õ‡∏¥‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‚Äú‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏ó‡∏ô‡∏≤‡∏¢‡πÑ‡∏´‡∏°‚Äù
"""
    res = requests.post(OLLAMA_URL, json={
        "model": OLLAMA_MODEL,
        "prompt": prompt,
        "stream": False
    })
    return res.json().get("response", "").strip()


def is_positive_reply(message: str) -> bool:
    """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ß‡πà‡∏≤‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏¢‡∏¥‡∏ô‡∏¢‡∏≠‡∏°‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏ó‡∏ô‡∏≤‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà"""
    text = message.strip().lower()

    positive_keywords = ["‡∏ï‡∏Å‡∏•‡∏á", "‡πÇ‡∏≠‡πÄ‡∏Ñ", "‡πÑ‡∏î‡πâ", "‡∏Ñ‡∏£‡∏±‡∏ö", "‡∏Ñ‡πà‡∏∞", "‡πÄ‡∏´‡πá‡∏ô‡∏î‡πâ‡∏ß‡∏¢", "‡∏¢‡∏¥‡∏ô‡∏¢‡∏≠‡∏°", "yes", "ok", "agree"]
    negative_keywords = ["‡πÑ‡∏°‡πà", "no", "‡∏¢‡∏±‡∏á", "‡∏õ‡∏è‡∏¥‡πÄ‡∏™‡∏ò", "‡πÑ‡∏°‡πà‡∏ï‡∏Å‡∏•‡∏á", "‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏±‡∏ö", "‡πÑ‡∏°‡πà‡∏Ñ‡πà‡∏∞"]

    # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ "‡πÑ‡∏°‡πà" ‡∏≠‡∏¢‡∏π‡πà‡∏Å‡πà‡∏≠‡∏ô‡∏Ñ‡∏≥‡∏¢‡∏¥‡∏ô‡∏¢‡∏≠‡∏° ‡πÄ‡∏ä‡πà‡∏ô "‡πÑ‡∏°‡πà‡∏ï‡∏Å‡∏•‡∏á" ‡∏´‡∏£‡∏∑‡∏≠ "‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà"
    if any(neg in text for neg in negative_keywords):
        return False

    if any(pos in text for pos in positive_keywords):
        return True

    # ‚úÖ 2. ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‚Üí ‡πÉ‡∏ä‡πâ Ollama ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ï‡πà‡∏≠
    prompt = f"""
‡∏à‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ß‡πà‡∏≤ ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡∏™‡∏∑‡πà‡∏≠‡∏ñ‡∏∂‡∏á‡∏Å‡∏≤‡∏£ '‡∏ï‡∏Å‡∏•‡∏á' ‡∏´‡∏£‡∏∑‡∏≠ '‡∏¢‡∏¥‡∏ô‡∏¢‡∏≠‡∏°' ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà

‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: "{message}"

‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏Ñ‡∏≥‡πÄ‡∏î‡∏µ‡∏¢‡∏ß:
- ‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πà ‡∏ï‡∏≠‡∏ö‡∏ß‡πà‡∏≤ TRUE
- ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà ‡∏ï‡∏≠‡∏ö‡∏ß‡πà‡∏≤ FALSE
"""
    try:
        res = requests.post(OLLAMA_URL, json={
            "model": OLLAMA_MODEL,
            "prompt": prompt,
            "stream": False
        })
        reply = res.json().get("response", "").strip().lower()
        print(f"ü§ñ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÇ‡∏î‡∏¢ AI: {reply}")
        return "true" in reply
    except Exception as e:
        print("‚ùå ‡∏ï‡∏£‡∏ß‡∏à‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ:", e)
        return False


# ===== ROUTES =====
@app.route("/")
def home():
    return render_template("index.html")


@app.route("/query", methods=["POST"])
def query():
    global lawyer_data
    data = request.get_json()
    question = data.get("question", "").strip()
    if not question:
        return jsonify({"error": "‚ùå ‡πÇ‡∏õ‡∏£‡∏î‡∏£‡∏∞‡∏ö‡∏∏‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°"}), 400

    # 1Ô∏è‚É£ ‡∏´‡∏≤ context ‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢
    contexts = search_similar(question, law_texts, law_index)
    context_text = "\n\n".join([t for t, _ in contexts])

    # 2Ô∏è‚É£ ‡∏´‡∏≤ lawyer ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á
    lawyer_matches = search_similar(question, [t for t in lawyer_texts], lawyer_index, top_k=3)
    related_lawyers = []
    for text, _ in lawyer_matches:
        for l in lawyer_data:
            if l["name"] in text:
                related_lawyers.append(l)

    # 3Ô∏è‚É£ ‡∏à‡∏≥‡∏ó‡∏ô‡∏≤‡∏¢‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÑ‡∏ß‡πâ
    if related_lawyers:
        app.config["last_lawyer"] = related_lawyers[0]

    # 4Ô∏è‚É£ ‡πÉ‡∏´‡πâ AI ‡∏ï‡∏≠‡∏ö
    answer = generate_answer(context_text, related_lawyers, question)

    return jsonify({
        "answer": answer,
        "context": context_text,
        "lawyers": related_lawyers
    })


@app.route("/confirm", methods=["POST"])
def confirm_contact():
    """Route ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏ó‡∏ô‡∏≤‡∏¢ (AI ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏≠‡∏á)"""
    data = request.get_json()
    message = data.get("message", "").strip()
    if not message:
        return jsonify({"error": "‚ùå ‡πÇ‡∏õ‡∏£‡∏î‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°"}), 400
    if is_positive_reply(message):
        if "last_lawyer" not in app.config:
            return jsonify({"error": "‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏ô‡∏≤‡∏¢‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î"}), 400
        return jsonify({
            "message": "üìû ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏ó‡∏ô‡∏≤‡∏¢",
            "lawyer": app.config["last_lawyer"]
        })
    else:
        return jsonify({"message": "‡πÇ‡∏≠‡πÄ‡∏Ñ ‡∏´‡∏ß‡∏±‡∏á‡∏ß‡πà‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô"}), 200


# ===== MAIN =====
if __name__ == "__main__":
    os.makedirs("cache", exist_ok=True)
    os.makedirs("embeddings", exist_ok=True)

    # ‡πÇ‡∏´‡∏•‡∏î‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢
    if os.path.exists(TEXTS_LAW) and os.path.exists(INDEX_LAW):
        print("üìÇ ‡πÇ‡∏´‡∏•‡∏î‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡∏à‡∏≤‡∏Å‡πÅ‡∏Ñ‡∏ä")
        with open(TEXTS_LAW, "r", encoding="utf-8") as f:
            law_texts = json.load(f)
        law_index = faiss.read_index(INDEX_LAW)
    else:
        law_texts, law_index = build_law_dataset()
        faiss.write_index(law_index, INDEX_LAW)
        with open(TEXTS_LAW, "w", encoding="utf-8") as f:
            json.dump(law_texts, f, ensure_ascii=False)

    # ‡πÇ‡∏´‡∏•‡∏î‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏ô‡∏≤‡∏¢
    if os.path.exists(TEXTS_LAWYER) and os.path.exists(INDEX_LAWYER):
        print("üìÇ ‡πÇ‡∏´‡∏•‡∏î‡∏ó‡∏ô‡∏≤‡∏¢‡∏à‡∏≤‡∏Å‡πÅ‡∏Ñ‡∏ä")
        with open(TEXTS_LAWYER, "r", encoding="utf-8") as f:
            lawyer_data = json.load(f)
        lawyer_texts = [f"{d['name']} - ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç: {', '.join(d['expertise'])}" for d in lawyer_data]
        lawyer_index = faiss.read_index(INDEX_LAWYER)
    else:
        lawyer_data, lawyer_texts, lawyer_index = build_lawyer_dataset()
        faiss.write_index(lawyer_index, INDEX_LAWYER)
        with open(TEXTS_LAWYER, "w", encoding="utf-8") as f:
            json.dump(lawyer_data, f, ensure_ascii=False)

    print("\nüéØ ‡∏£‡∏∞‡∏ö‡∏ö RAG ‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢ + ‡∏ó‡∏ô‡∏≤‡∏¢ (AI ‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠) ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô!")
    app.run(host="0.0.0.0", port=8000, debug=True)
